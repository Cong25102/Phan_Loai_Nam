# 1. Import th∆∞ vi·ªán
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# 2. ƒê·ªçc d·ªØ li·ªáu
df = pd.read_csv('mushrooms.csv')  # ƒê·∫£m b·∫£o b·∫°n c√≥ file n√†y trong th∆∞ m·ª•c l√†m vi·ªác

# 3. Ki·ªÉm tra c·∫•u tr√∫c
print("K√≠ch th∆∞·ªõc d·ªØ li·ªáu:", df.shape)
print("\nTh√¥ng tin d·ªØ li·ªáu:")
print(df.info())

# 4. Ph√¢n t√≠ch bi·∫øn m·ª•c ti√™u (c·ªôt 'class': edible=e, poisonous=p)
plt.figure(figsize=(6,4))
sns.countplot(x='class', data=df, palette='Set2')
plt.title('Ph√¢n ph·ªëi bi·∫øn m·ª•c ti√™u (class)')
plt.xlabel('Lo·∫°i n·∫•m')
plt.ylabel('S·ªë l∆∞·ª£ng')
plt.show()

# 5. Ph√¢n t√≠ch ƒë·∫∑c tr∆∞ng ph√¢n lo·∫°i (v√¨ to√†n b·ªô d·ªØ li·ªáu l√† categorical)
for col in df.columns:
    if col != 'class':
        plt.figure(figsize=(6,4))
        sns.countplot(x=col, data=df, order=df[col].value_counts().index, palette='Set3')
        plt.title(f'T·∫ßn su·∫•t gi√° tr·ªã c·ªßa ƒë·∫∑c tr∆∞ng: {col}')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()

# 6. Ki·ªÉm tra d·ªØ li·ªáu thi·∫øu
missing = df.isnull().sum()
print("\nS·ªë l∆∞·ª£ng gi√° tr·ªã thi·∫øu m·ªói c·ªôt:")
print(missing[missing > 0])

# 7. M√£ h√≥a d·ªØ li·ªáu ƒë·ªÉ t√≠nh ma tr·∫≠n t∆∞∆°ng quan
df_encoded = df.apply(lambda x: pd.factorize(x)[0])  # Chuy·ªÉn categorical th√†nh s·ªë nguy√™n

# 8. Ma tr·∫≠n t∆∞∆°ng quan
plt.figure(figsize=(12,10))
corr_matrix = df_encoded.corr()
sns.heatmap(corr_matrix, cmap='coolwarm', annot=False)
plt.title('Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c ƒë·∫∑c tr∆∞ng')
plt.show()

# Thay th·∫ø d·ªØ li·ªáu thi·∫øu b·∫±ng mode
for col in df.columns:
    if df[col].isnull().sum() > 0:
        mode_val = df[col].mode()[0]
        df[col].fillna(mode_val, inplace=True)



from sklearn.preprocessing import OneHotEncoder

df_encoded = pd.get_dummies(df.drop('class', axis=1))  # lo·∫°i b·ªè bi·∫øn m·ª•c ti√™u

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_encoded)

df['odor_spore'] = df['odor'] + "_" + df['spore-print-color']

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense

input_dim = df_encoded.shape[1]
encoding_dim = 32

input_layer = Input(shape=(input_dim,))
encoded = Dense(64, activation='relu')(input_layer)
encoded = Dense(encoding_dim, activation='relu')(encoded)
decoded = Dense(64, activation='relu')(encoded)
decoded = Dense(input_dim, activation='sigmoid')(decoded)

autoencoder = Model(inputs=input_layer, outputs=decoded)
encoder = Model(inputs=input_layer, outputs=encoded)

autoencoder.compile(optimizer='adam', loss='mse')
autoencoder.fit(df_encoded, df_encoded, epochs=50, batch_size=32, validation_split=0.2)

features_autoencoded = encoder.predict(df_encoded)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.optimizers import Adam

# ƒê·ªçc d·ªØ li·ªáu
df = pd.read_csv('mushrooms.csv')

# Bi·∫øn m·ª•c ti√™u
y = df['class'].map({'e': 0, 'p': 1})  # edible=0, poisonous=1

# X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu
for col in df.columns:
    if df[col].isnull().sum() > 0:
        df[col].fillna(df[col].mode()[0], inplace=True)

# One-Hot Encoding cho ƒë·∫∑c tr∆∞ng
X_encoded = pd.get_dummies(df.drop('class', axis=1))

# Chu·∫©n h√≥a
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_encoded)

# T√°ch d·ªØ li·ªáu
X_train_A, X_test_A, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Hu·∫•n luy·ªán m√¥ h√¨nh
model_A = RandomForestClassifier(random_state=42)
model_A.fit(X_train_A, y_train)

# D·ª± ƒëo√°n v√† ƒë√°nh gi√°
y_pred_A = model_A.predict(X_test_A)
print("üîç K·∫øt qu·∫£ v·ªõi Lu·ªìng A (Truy·ªÅn th·ªëng):")
print("Accuracy:", accuracy_score(y_test, y_pred_A))
print(classification_report(y_test, y_pred_A))

# Ki·∫øn tr√∫c Autoencoder
input_dim = X_encoded.shape[1]
encoding_dim = 32

input_layer = Input(shape=(input_dim,))
encoded = Dense(64, activation='relu')(input_layer)
encoded = Dense(encoding_dim, activation='relu')(encoded)
decoded = Dense(64, activation='relu')(encoded)
decoded = Dense(input_dim, activation='sigmoid')(decoded)

autoencoder = Model(inputs=input_layer, outputs=decoded)
encoder = Model(inputs=input_layer, outputs=encoded)

# Hu·∫•n luy·ªán Autoencoder
autoencoder.compile(optimizer=Adam(), loss='mse')
autoencoder.fit(X_encoded, X_encoded, epochs=50, batch_size=32, validation_split=0.2, verbose=0)

# Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
X_autoencoded = encoder.predict(X_encoded)

# T√°ch d·ªØ li·ªáu
X_train_B, X_test_B, _, _ = train_test_split(X_autoencoded, y, test_size=0.2, random_state=42)

# Hu·∫•n luy·ªán m√¥ h√¨nh
model_B = RandomForestClassifier(random_state=42)
model_B.fit(X_train_B, y_train)

# D·ª± ƒëo√°n v√† ƒë√°nh gi√°
y_pred_B = model_B.predict(X_test_B)
print("üîç K·∫øt qu·∫£ v·ªõi Lu·ªìng B (Autoencoder):")
print("Accuracy:", accuracy_score(y_test, y_pred_B))
print(classification_report(y_test, y_pred_B))

from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# B·ªô d·ªØ li·ªáu
X_A = X_scaled
X_B = features_autoencoded

# T√°ch d·ªØ li·ªáu
X_train_A, X_test_A, y_train, y_test = train_test_split(X_A, y, test_size=0.2, random_state=42)
X_train_B, X_test_B, _, _ = train_test_split(X_B, y, test_size=0.2, random_state=42)

# Kh·ªüi t·∫°o m√¥ h√¨nh
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss')
}

# Hu·∫•n luy·ªán v√† ƒë√°nh gi√°
results = []

for name, model in models.items():
    # Lu·ªìng A
    model.fit(X_train_A, y_train)
    y_pred_A = model.predict(X_test_A)
    results.append({
        "Model": name,
        "Feature Set": "Lu·ªìng A",
        "Accuracy": accuracy_score(y_test, y_pred_A),
        "Precision": precision_score(y_test, y_pred_A),
        "Recall": recall_score(y_test, y_pred_A),
        "F1-score": f1_score(y_test, y_pred_A),
        "ROC-AUC": roc_auc_score(y_test, y_pred_A)
    })

    # Lu·ªìng B
    model.fit(X_train_B, y_train)
    y_pred_B = model.predict(X_test_B)
    results.append({
        "Model": name,
        "Feature Set": "Lu·ªìng B",
        "Accuracy": accuracy_score(y_test, y_pred_B),
        "Precision": precision_score(y_test, y_pred_B),
        "Recall": recall_score(y_test, y_pred_B),
        "F1-score": f1_score(y_test, y_pred_B),
        "ROC-AUC": roc_auc_score(y_test, y_pred_B)
    })

# Chuy·ªÉn k·∫øt qu·∫£ th√†nh b·∫£ng
results_df = pd.DataFrame(results)
print("üìä B·∫£ng so s√°nh hi·ªáu su·∫•t m√¥ h√¨nh:")
print(results_df)
